<!--
This HTML is auto-generated.  DO NOT EDIT THIS FILE!  If you are writing a new
PEP, see http://www.python.org/dev/peps/pep-0001 for instructions and links
to templates.  DO NOT USE THIS HTML FILE AS YOUR TEMPLATE!
-->
<table class="rfc2822 docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">PEP:</th><td class="field-body">574</td>
</tr>
<tr class="field"><th class="field-name">Title:</th><td class="field-body">Pickle protocol 5 with out-of-band data</td>
</tr>
<tr class="field"><th class="field-name">Version:</th><td class="field-body">$Revision$</td>
</tr>
<tr class="field"><th class="field-name">Last-Modified:</th><td class="field-body"><a class="reference external" href="https://hg.python.org/peps/file/tip/pep-0574.txt">$Date$</a></td>
</tr>
<tr class="field"><th class="field-name">Author:</th><td class="field-body">Antoine Pitrou &lt;solipsis&#32;&#97;t&#32;pitrou.net&gt;</td>
</tr>
<tr class="field"><th class="field-name">Status:</th><td class="field-body">Draft</td>
</tr>
<tr class="field"><th class="field-name">Type:</th><td class="field-body">Standards Track</td>
</tr>
<tr class="field"><th class="field-name">Content-Type:</th><td class="field-body"><a class="reference external" href="/dev/peps/pep-0012">text/x-rst</a></td>
</tr>
<tr class="field"><th class="field-name">Created:</th><td class="field-body">23-Mar-2018</td>
</tr>
<tr class="field"><th class="field-name">Post-History:</th><td class="field-body">28-Mar-2018</td>
</tr>
<tr class="field"><th class="field-name">Resolution:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
<hr />
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#abstract" id="id9">Abstract</a></li>
<li><a class="reference internal" href="#rationale" id="id10">Rationale</a></li>
<li><a class="reference internal" href="#example" id="id11">Example</a></li>
<li><a class="reference internal" href="#producer-api" id="id12">Producer API</a><ul>
<li><a class="reference internal" href="#picklebuffer-objects" id="id13">PickleBuffer objects</a></li>
</ul>
</li>
<li><a class="reference internal" href="#consumer-api" id="id14">Consumer API</a></li>
<li><a class="reference internal" href="#protocol-changes" id="id15">Protocol changes</a></li>
<li><a class="reference internal" href="#caveats" id="id16">Caveats</a><ul>
<li><a class="reference internal" href="#mutability" id="id17">Mutability</a></li>
<li><a class="reference internal" href="#data-sharing" id="id18">Data sharing</a></li>
</ul>
</li>
<li><a class="reference internal" href="#alternatives" id="id19">Alternatives</a></li>
<li><a class="reference internal" href="#open-questions" id="id20">Open questions</a></li>
<li><a class="reference internal" href="#related-work" id="id21">Related work</a></li>
<li><a class="reference internal" href="#acknowledgements" id="id22">Acknowledgements</a></li>
<li><a class="reference internal" href="#references" id="id23">References</a></li>
<li><a class="reference internal" href="#copyright" id="id24">Copyright</a></li>
</ul>
</div>
<div class="section" id="abstract">
<h1><a class="toc-backref" href="#id9">Abstract</a></h1>
<p>This PEP proposes to standardize a new pickle protocol version, and
accompanying APIs to take full advantage of it:</p>
<ol class="arabic simple">
<li>A new pickle protocol version (5) to cover the extra metadata needed
for out-of-band data buffers.</li>
<li>A new <tt class="docutils literal">PickleBuffer</tt> type for <tt class="docutils literal">__reduce_ex__</tt> implementations
to return out-of-band data buffers.</li>
<li>A new <tt class="docutils literal">buffer_callback</tt> parameter when pickling, to handle out-of-band
data buffers.</li>
<li>A new <tt class="docutils literal">buffers</tt> parameter when unpickling to provide out-of-band data
buffers.</li>
</ol>
<p>The PEP guarantees unchanged behaviour for anyone not using the new APIs.</p>
</div>
<div class="section" id="rationale">
<h1><a class="toc-backref" href="#id10">Rationale</a></h1>
<p>The pickle protocol was originally designed in 1995 for on-disk persistency
of arbitrary Python objects.  The performance of a 1995-era storage medium
probably made it irrelevant to focus on performance metrics such as
use of RAM bandwidth when copying temporary data before writing it to disk.</p>
<p>Nowadays the pickle protocol sees a growing use in applications where most
of the data isn't ever persisted to disk (or, when it is, it uses a portable
format instead of Python-specific).  Instead, pickle is being used to transmit
data and commands from one process to another, either on the same machine
or on multiple machines.  Those applications will sometimes deal with very
large data (such as Numpy arrays or Pandas dataframes) that need to be
transferred around.  For those applications, pickle is currently
wasteful as it imposes spurious memory copies of the data being serialized.</p>
<p>As a matter of fact, the standard <tt class="docutils literal">multiprocessing</tt> module uses pickle
for serialization, and therefore also suffers from this problem when
sending large data to another process.</p>
<p>Third-party Python libraries, such as Dask <a class="footnote-reference" href="#dask" id="id1">[1]</a>, PyArrow <a class="footnote-reference" href="#pyarrow" id="id2">[4]</a>
and IPyParallel <a class="footnote-reference" href="#ipyparallel" id="id3">[3]</a>, have started implementing alternative
serialization schemes with the explicit goal of avoiding copies on large
data.  Implementing a new serialization scheme is difficult and often
leads to reduced generality (since many Python objects support pickle
but not the new serialization scheme).  Falling back on pickle for
unsupported types is an option, but then you get back the spurious
memory copies you wanted to avoid in the first place.  For example,
<tt class="docutils literal">dask</tt> is able to avoid memory copies for Numpy arrays and
built-in containers thereof (such as lists or dicts containing Numpy
arrays), but if a large Numpy array is an attribute of a user-defined
object, <tt class="docutils literal">dask</tt> will serialize the user-defined object as a pickle
stream, leading to memory copies.</p>
<p>The common theme of these third-party serialization efforts is to generate
a stream of object metadata (which contains pickle-like information about
the objects being serialized) and a separate stream of zero-copy buffer
objects for the payloads of large objects.  Note that, in this scheme,
small objects such as ints, etc. can be dumped together with the metadata
stream.  Refinements can include opportunistic compression of large data
depending on its type and layout, like <tt class="docutils literal">dask</tt> does.</p>
<p>This PEP aims to make <tt class="docutils literal">pickle</tt> usable in a way where large data is handled
as a separate stream of zero-copy buffers, letting the application handle
those buffers optimally.</p>
</div>
<div class="section" id="example">
<h1><a class="toc-backref" href="#id11">Example</a></h1>
<p>To keep the example simple and avoid requiring knowledge of third-party
libraries, we will focus here on a bytearray object (but the issue is
conceptually the same with more sophisticated objects such as Numpy arrays).
Like most objects, the bytearray object isn't immediately understood by
the pickle module and must therefore specify its decomposition scheme.</p>
<p>Here is how a bytearray object currently decomposes for pickling:</p>
<pre class="literal-block">
&gt;&gt;&gt; b.__reduce_ex__(4)
(&lt;class 'bytearray'&gt;, (b'abc',), None)
</pre>
<p>This is because the <tt class="docutils literal">bytearray.__reduce_ex__</tt> implementation reads
morally as follows:</p>
<pre class="literal-block">
class bytearray:

   def __reduce_ex__(self, protocol):
      if protocol == 4:
         return type(self), bytes(self), None
      # Legacy code for earlier protocols omitted
</pre>
<p>In turn it produces the following pickle code:</p>
<pre class="literal-block">
&gt;&gt;&gt; pickletools.dis(pickletools.optimize(pickle.dumps(b, protocol=4)))
    0: \x80 PROTO      4
    2: \x95 FRAME      30
   11: \x8c SHORT_BINUNICODE 'builtins'
   21: \x8c SHORT_BINUNICODE 'bytearray'
   32: \x93 STACK_GLOBAL
   33: C    SHORT_BINBYTES b'abc'
   38: \x85 TUPLE1
   39: R    REDUCE
   40: .    STOP
</pre>
<p>(the call to <tt class="docutils literal">pickletools.optimize</tt> above is only meant to make the
pickle stream more readable by removing the MEMOIZE opcodes)</p>
<p>We can notice several things about the bytearray's payload (the sequence
of bytes <tt class="docutils literal">b'abc'</tt>):</p>
<ul class="simple">
<li><tt class="docutils literal">bytearray.__reduce_ex__</tt> produces a first copy by instantiating a
new bytes object from the bytearray's data.</li>
<li><tt class="docutils literal">pickle.dumps</tt> produces a second copy when inserting the contents of
that bytes object into the pickle stream, after the SHORT_BINBYTES opcode.</li>
<li>Furthermore, when deserializing the pickle stream, a temporary bytes
object is created when the SHORT_BINBYTES opcode is encountered (inducing
a data copy).</li>
</ul>
<p>What we really want is something like the following:</p>
<ul class="simple">
<li><tt class="docutils literal">bytearray.__reduce_ex__</tt> produces a <em>view</em> of the bytearray's data.</li>
<li><tt class="docutils literal">pickle.dumps</tt> doesn't try to copy that data into the pickle stream
but instead passes the buffer view to its caller (which can decide on the
most efficient handling of that buffer).</li>
<li>When deserializing, <tt class="docutils literal">pickle.loads</tt> takes the pickle stream and the
buffer view separately, and passes the buffer view directly to the
bytearray constructor.</li>
</ul>
<p>We see that several conditions are required for the above to work:</p>
<ul class="simple">
<li><tt class="docutils literal">__reduce__</tt> or <tt class="docutils literal">__reduce_ex__</tt> must be able to return <em>something</em>
that indicates a serializable no-copy buffer view.</li>
<li>The pickle protocol must be able to represent references to such buffer
views, instructing the unpickler that it may have to get the actual buffer
out of band.</li>
<li>The <tt class="docutils literal">pickle.Pickler</tt> API must provide its caller with a way
to receive such buffer views while serializing.</li>
<li>The <tt class="docutils literal">pickle.Unpickler</tt> API must similarly allow its caller to provide
the buffer views required for deserialization.</li>
<li>For compatibility, the pickle protocol must also be able to contain direct
serializations of such buffer views, such that current uses of the <tt class="docutils literal">pickle</tt>
API don't have to be modified if they are not concerned with memory copies.</li>
</ul>
</div>
<div class="section" id="producer-api">
<h1><a class="toc-backref" href="#id12">Producer API</a></h1>
<p>We are introducing a new type <tt class="docutils literal">pickle.PickleBuffer</tt> which can be
instantiated from any buffer-supporting object, and is specifically meant
to be returned from <tt class="docutils literal">__reduce__</tt> implementations:</p>
<pre class="literal-block">
class bytearray:

   def __reduce_ex__(self, protocol):
      if protocol == 5:
         return type(self), PickleBuffer(self), None
      # Legacy code for earlier protocols omitted
</pre>
<p><tt class="docutils literal">PickleBuffer</tt> is a simple wrapper that doesn't have all the memoryview
semantics and functionality, but is specifically recognized by the <tt class="docutils literal">pickle</tt>
module if protocol 5 or higher is enabled.  It is an error to try to
serialize a <tt class="docutils literal">PickleBuffer</tt> with pickle protocol version 4 or earlier.</p>
<p>Only the raw <em>data</em> of the <tt class="docutils literal">PickleBuffer</tt> will be considered by the
<tt class="docutils literal">pickle</tt> module.  Any type-specific <em>metadata</em> (such as shapes or
datatype) must be returned separately by the type's <tt class="docutils literal">__reduce__</tt>
implementation, as is already the case.</p>
<div class="section" id="picklebuffer-objects">
<h2><a class="toc-backref" href="#id13">PickleBuffer objects</a></h2>
<p>The <tt class="docutils literal">PickleBuffer</tt> class supports a very simple Python API.  Its constructor
takes a single <a class="reference external" href="/dev/peps/pep-3118">PEP 3118</a>-compatible object <a class="footnote-reference" href="#pep-3118" id="id4">[6]</a>.  <tt class="docutils literal">PickleBuffer</tt>
objects themselves support the buffer protocol, so consumers can
call <tt class="docutils literal"><span class="pre">memoryview(...)</span></tt> on them to get additional information
about the underlying buffer (such as the original type, shape, etc.).
In addition, <tt class="docutils literal">PickleBuffer</tt> objects can be explicitly released using
their <tt class="docutils literal">release()</tt> method.</p>
<p>On the C side, a simple API will be provided to create and inspect
PickleBuffer objects:</p>
<p><tt class="docutils literal">PyObject *PyPickleBuffer_FromObject(PyObject *obj)</tt></p>
<blockquote>
Create a <tt class="docutils literal">PickleBuffer</tt> object holding a view over the <a class="reference external" href="/dev/peps/pep-3118">PEP 3118</a>-compatible
<em>obj</em>.</blockquote>
<p><tt class="docutils literal">PyPickleBuffer_Check(PyObject *obj)</tt></p>
<blockquote>
Return whether <em>obj</em> is a <tt class="docutils literal">PickleBuffer</tt> instance.</blockquote>
<p><tt class="docutils literal">const Py_buffer *PyPickleBuffer_GetBuffer(PyObject *picklebuf)</tt></p>
<blockquote>
Return a pointer to the internal <tt class="docutils literal">Py_buffer</tt> owned by the <tt class="docutils literal">PickleBuffer</tt>
instance.  An exception is raised if the buffer is released.</blockquote>
<p><tt class="docutils literal">int PyPickleBuffer_Release(PyObject *picklebuf)</tt></p>
<blockquote>
Release the <tt class="docutils literal">PickleBuffer</tt> instance's underlying buffer.</blockquote>
<p><tt class="docutils literal">PickleBuffer</tt> can wrap any kind of buffer, including non-contiguous
buffers.  It's up to consumers to decide how best to handle different kinds
of buffers (for example, some consumers may find it acceptable to make a
contiguous copy of non-contiguous buffers).</p>
</div>
</div>
<div class="section" id="consumer-api">
<h1><a class="toc-backref" href="#id14">Consumer API</a></h1>
<p><tt class="docutils literal">pickle.Pickler.__init__</tt> and <tt class="docutils literal">pickle.dumps</tt> are augmented with an additional
<tt class="docutils literal">buffer_callback</tt> parameter:</p>
<pre class="literal-block">
class Pickler:
   def __init__(self, file, protocol=None, ..., buffer_callback=None):
      &quot;&quot;&quot;
      If *buffer_callback* is not None, then it is called with a list
      of out-of-band buffer views when deemed necessary (this could be
      once every buffer, or only after a certain size is reached,
      or once at the end, depending on implementation details). The
      callback should arrange to store or transmit those buffers without
      changing their order.

      If *buffer_callback* is None (the default), buffer views are
      serialized into *file* as part of the pickle stream.

      It is an error if *buffer_callback* is not None and *protocol* is
      None or smaller than 5.
      &quot;&quot;&quot;

def pickle.dumps(obj, protocol=None, *, ..., buffer_callback=None):
   &quot;&quot;&quot;
   See above for *buffer_callback*.
   &quot;&quot;&quot;
</pre>
<p><tt class="docutils literal">pickle.Unpickler.__init__</tt> and <tt class="docutils literal">pickle.loads</tt> are augmented with an
additional <tt class="docutils literal">buffers</tt> parameter:</p>
<pre class="literal-block">
class Unpickler:
   def __init__(file, *, ..., buffers=None):
      &quot;&quot;&quot;
      If *buffers* is not None, it should be an iterable of buffer-enabled
      objects that is consumed each time the pickle stream references
      an out-of-band buffer view.  Such buffers have been given in order
      to the *buffer_callback* of a Pickler object.

      If *buffers* is None (the default), then the buffers are taken
      from the pickle stream, assuming they are serialized there.
      It is an error for *buffers* to be None if the pickle stream
      was produced with a non-None *buffer_callback*.
      &quot;&quot;&quot;

def pickle.loads(data, *, ..., buffers=None):
   &quot;&quot;&quot;
   See above for *buffers*.
   &quot;&quot;&quot;
</pre>
</div>
<div class="section" id="protocol-changes">
<h1><a class="toc-backref" href="#id15">Protocol changes</a></h1>
<p>Three new opcodes are introduced:</p>
<ul class="simple">
<li><tt class="docutils literal">BYTEARRAY</tt> creates a bytearray from the data following it in the pickle
stream and pushes it on the stack (just like <tt class="docutils literal">BINBYTES8</tt> does for bytes
objects);</li>
<li><tt class="docutils literal">NEXT_BUFFER</tt> fetches a buffer from the <tt class="docutils literal">buffers</tt> iterable and pushes
it on the stack.</li>
<li><tt class="docutils literal">READONLY_BUFFER</tt> makes a readonly view of the top of the stack.</li>
</ul>
<p>When pickling encounters a <tt class="docutils literal">PickleBuffer</tt>, there can be four cases:</p>
<ul class="simple">
<li>If a <tt class="docutils literal">buffer_callback</tt> is given and the <tt class="docutils literal">PickleBuffer</tt> is writable,
the <tt class="docutils literal">PickleBuffer</tt> is given to the callback and a <tt class="docutils literal">NEXT_BUFFER</tt> opcode
is appended to the pickle stream.</li>
<li>If a <tt class="docutils literal">buffer_callback</tt> is given and the <tt class="docutils literal">PickleBuffer</tt> is readonly,
the <tt class="docutils literal">PickleBuffer</tt> is given to the callback and a <tt class="docutils literal">NEXT_BUFFER</tt> opcode
is appended to the pickle stream, followed by a <tt class="docutils literal">READONLY_BUFFER</tt> opcode.</li>
<li>If no <tt class="docutils literal">buffer_callback</tt> is given and the <tt class="docutils literal">PickleBuffer</tt> is writable,
it is serialized into the pickle stream as if it were a <tt class="docutils literal">bytearray</tt> object.</li>
<li>If no <tt class="docutils literal">buffer_callback</tt> is given and the <tt class="docutils literal">PickleBuffer</tt> is readonly,
it is serialized into the pickle stream as if it were a <tt class="docutils literal">bytes</tt> object.</li>
</ul>
<p>The distinction between readonly and writable buffers is explained below
(see &quot;Mutability&quot;).</p>
</div>
<div class="section" id="caveats">
<h1><a class="toc-backref" href="#id16">Caveats</a></h1>
<div class="section" id="mutability">
<h2><a class="toc-backref" href="#id17">Mutability</a></h2>
<p><a class="reference external" href="/dev/peps/pep-3118">PEP 3118</a> buffers <a class="footnote-reference" href="#pep-3118" id="id5">[6]</a> can be readonly or writable.  Some objects,
such as Numpy arrays, need to be backed by a mutable buffer for full
operation.  Pickle consumers that use the <tt class="docutils literal">buffer_callback</tt> and <tt class="docutils literal">buffers</tt>
arguments will have to be careful to recreate mutable buffers.  When doing
I/O, this implies using buffer-passing API variants such as <tt class="docutils literal">readinto</tt>
(which are also often preferrable for performance).</p>
</div>
<div class="section" id="data-sharing">
<h2><a class="toc-backref" href="#id18">Data sharing</a></h2>
<p>If you pickle and then unpickle an object in the same process, passing
out-of-band buffer views, then the unpickled object may be backed by the
same buffer as the original pickled object.</p>
<p>For example, it might be reasonable to implement reduction of a Numpy array
as follows (crucial metadata such as shapes is omitted for simplicity):</p>
<pre class="literal-block">
class ndarray:

   def __reduce_ex__(self, protocol):
      if protocol == 5:
         return numpy.frombuffer, (PickleBuffer(self), self.dtype)
      # Legacy code for earlier protocols omitted
</pre>
<p>Then simply passing the PickleBuffer around from <tt class="docutils literal">dumps</tt> to <tt class="docutils literal">loads</tt>
will produce a new Numpy array sharing the same underlying memory as the
original Numpy object (and, incidentally, keeping it alive):</p>
<pre class="literal-block">
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.zeros(10)
&gt;&gt;&gt; a[0]
0.0
&gt;&gt;&gt; buffers = []
&gt;&gt;&gt; data = pickle.dumps(a, protocol=5, buffer_callback=buffers.extend)
&gt;&gt;&gt; b = pickle.loads(data, buffers=buffers)
&gt;&gt;&gt; b[0] = 42
&gt;&gt;&gt; a[0]
42.0
</pre>
<p>This won't happen with the traditional <tt class="docutils literal">pickle</tt> API (i.e. without passing
<tt class="docutils literal">buffers</tt> and <tt class="docutils literal">buffer_callback</tt> parameters), because then the buffer view
is serialized inside the pickle stream with a copy.</p>
</div>
</div>
<div class="section" id="alternatives">
<h1><a class="toc-backref" href="#id19">Alternatives</a></h1>
<p>The <tt class="docutils literal">pickle</tt> persistence interface is a way of storing references to
designated objects in the pickle stream while handling their actual
serialization out of band.  For example, one might consider the following
for zero-copy serialization of bytearrays:</p>
<pre class="literal-block">
class MyPickle(pickle.Pickler):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.buffers = []

    def persistent_id(self, obj):
        if type(obj) is not bytearray:
            return None
        else:
            index = len(self.buffers)
            self.buffers.append(obj)
            return ('bytearray', index)


class MyUnpickle(pickle.Unpickler):

    def __init__(self, *args, buffers, **kwargs):
        super().__init__(*args, **kwargs)
        self.buffers = buffers

    def persistent_load(self, pid):
        type_tag, index = pid
        if type_tag == 'bytearray':
            return self.buffers[index]
        else:
            assert 0  # unexpected type
</pre>
<p>This mechanism has two drawbacks:</p>
<ul class="simple">
<li>Each <tt class="docutils literal">pickle</tt> consumer must reimplement <tt class="docutils literal">Pickler</tt> and <tt class="docutils literal">Unpickler</tt>
subclasses, with custom code for each type of interest.  Essentially,
N pickle consumers end up each implementing custom code for M producers.
This is difficult (especially for sophisticated types such as Numpy
arrays) and poorly scalable.</li>
<li>Each object encountered by the pickle module (even simple built-in objects
such as ints and strings) triggers a call to the user's <tt class="docutils literal">persistent_id()</tt>
method, leading to a possible performance drop compared to nominal.</li>
</ul>
</div>
<div class="section" id="open-questions">
<h1><a class="toc-backref" href="#id20">Open questions</a></h1>
<p>Should <tt class="docutils literal">buffer_callback</tt> take a single buffers or a sequence of buffers?</p>
<ul class="simple">
<li>Taking a single buffer would allow returning a boolean indicating whether
the given buffer is serialized in-band or out-of-band.</li>
<li>Taking a sequence of buffers is potentially more efficient by reducing
function call overhead.</li>
</ul>
<p>Should it be allowed to serialize a <tt class="docutils literal">PickleBuffer</tt> in protocol 4 and earlier?
It would simply be serialized as a <tt class="docutils literal">bytes</tt> object (if read-only) or
<tt class="docutils literal">bytearray</tt> (if writable).</p>
<ul class="simple">
<li>It can make implementing <tt class="docutils literal">__reduce__</tt> simpler.</li>
<li>Serializing a <tt class="docutils literal">bytearray</tt> in protocol 4 makes a supplementary memory
copy when <tt class="docutils literal">bytearray.__reduce_ex__</tt> returns a <tt class="docutils literal">bytes</tt> object.  This
is a performance regression that may be overlooked by <tt class="docutils literal">__reduce__</tt>
implementors.</li>
</ul>
</div>
<div class="section" id="related-work">
<h1><a class="toc-backref" href="#id21">Related work</a></h1>
<p>Dask.distributed implements a custom zero-copy serialization with fallback
to pickle <a class="footnote-reference" href="#dask-serialization" id="id6">[2]</a>.</p>
<p>PyArrow implements zero-copy component-based serialization for a few
selected types <a class="footnote-reference" href="#pyarrow-serialization" id="id7">[5]</a>.</p>
<p><a class="reference external" href="/dev/peps/pep-0554">PEP 554</a> proposes hosting multiple interpreters in a single process, with
provisions for transferring buffers between interpreters as a communication
scheme <a class="footnote-reference" href="#pep-554" id="id8">[7]</a>.</p>
</div>
<div class="section" id="acknowledgements">
<h1><a class="toc-backref" href="#id22">Acknowledgements</a></h1>
<p>Thanks to the following people for early feedback: Nick Coghlan, Olivier
Grisel, Stefan Krah, MinRK, Matt Rocklin, Eric Snow.</p>
</div>
<div class="section" id="references">
<h1><a class="toc-backref" href="#id23">References</a></h1>
<table class="docutils footnote" frame="void" id="dask" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Dask.distributed -- A lightweight library for distributed computing
in Python
<a class="reference external" href="https://distributed.readthedocs.io/">https://distributed.readthedocs.io/</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="dask-serialization" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[2]</a></td><td>Dask.distributed custom serialization
<a class="reference external" href="https://distributed.readthedocs.io/en/latest/serialization.html">https://distributed.readthedocs.io/en/latest/serialization.html</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="ipyparallel" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[3]</a></td><td>IPyParallel -- Using IPython for parallel computing
<a class="reference external" href="https://ipyparallel.readthedocs.io/">https://ipyparallel.readthedocs.io/</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="pyarrow" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[4]</a></td><td>PyArrow -- A cross-language development platform for in-memory data
<a class="reference external" href="https://arrow.apache.org/docs/python/">https://arrow.apache.org/docs/python/</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="pyarrow-serialization" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[5]</a></td><td>PyArrow IPC and component-based serialization
<a class="reference external" href="https://arrow.apache.org/docs/python/ipc.html#component-based-serialization">https://arrow.apache.org/docs/python/ipc.html#component-based-serialization</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="pep-3118" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[6]</td><td><em>(<a class="fn-backref" href="#id4">1</a>, <a class="fn-backref" href="#id5">2</a>)</em> <a class="reference external" href="/dev/peps/pep-3118">PEP 3118</a> -- Revising the buffer protocol
<a class="reference external" href="https://www.python.org/dev/peps/pep-3118/">https://www.python.org/dev/peps/pep-3118/</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="pep-554" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id8">[7]</a></td><td><a class="reference external" href="/dev/peps/pep-0554">PEP 554</a> -- Multiple Interpreters in the Stdlib
<a class="reference external" href="https://www.python.org/dev/peps/pep-0554/">https://www.python.org/dev/peps/pep-0554/</a></td></tr>
</tbody>
</table>
</div>
<div class="section" id="copyright">
<h1><a class="toc-backref" href="#id24">Copyright</a></h1>
<p>This document has been placed into the public domain.</p>
<!-- Local Variables:
mode: indented-text
indent-tabs-mode: nil
sentence-end-double-space: t
fill-column: 70
coding: utf-8
End: -->
</div>

